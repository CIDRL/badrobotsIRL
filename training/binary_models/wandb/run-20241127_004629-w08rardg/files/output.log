{'activation_function': 'tanh', 'batch_size': 64, 'dense_units': 64, 'dropout_rate': 0.5, 'epochs': 500, 'fusion_type': 'intermediate', 'gru_units': 64, 'learning_rate': 0.01, 'loss': 'categorical_crossentropy', 'modality': 'audio', 'num_gru_layers': 3, 'optimizer': 'adam', 'recurrent_regularizer': 'l2', 'sequence_length': 90, 'use_bidirectional': True, 'use_norm': False, 'use_pca': False, 'use_stats': False}
training model
Train fold: ['p20nodbot' 'p29nodbot' 'p10nodbot' 'p4nodbot' 'p23nodbot' 'p21nodbot'
 'p26nodbot' 'p11nodbot' 'p7nodbot' 'p17nodbot' 'p12nodbot' 'p25nodbot'
 'p28nodbot' 'p14nodbot' 'p16nodbot' 'p8nodbot']
Validation fold: ['p2nodbot' 'p6nodbot' 'p9nodbot' 'p19nodbot' 'p22nodbot']
Test fold: ['p18nodbot' 'p27nodbot' 'p5nodbot']
Train shapes: (18972, 25) (18972,)
Validation shapes: (5653, 25) (5653,)
Test shapes: (3986, 25) (3986,)
Train sequences shape: (17548, 90, 25) (17548,)
X_train_sequences shape: (17548, 90, 25)
X_val_sequences shape: (5208, 90, 25)
X_test_sequences shape: (3719, 90, 25)
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 bidirectional (Bidirection  (None, 90, 128)           34944
 al)

 dropout (Dropout)           (None, 90, 128)           0

 batch_normalization (Batch  (None, 90, 128)           512
 Normalization)

 bidirectional_1 (Bidirecti  (None, 90, 128)           74496
 onal)

 dropout_1 (Dropout)         (None, 90, 128)           0

 batch_normalization_1 (Bat  (None, 90, 128)           512
 chNormalization)

 bidirectional_2 (Bidirecti  (None, 128)               74496
 onal)

 dropout_2 (Dropout)         (None, 128)               0

 batch_normalization_2 (Bat  (None, 128)               512
 chNormalization)

 dense (Dense)               (None, 64)                8256

 dense_1 (Dense)             (None, 2)                 130

=================================================================
Total params: 193858 (757.26 KB)
Trainable params: 193090 (754.26 KB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________
Epoch 1/500
275/275 - 31s - loss: 0.8751 - accuracy: 0.6601 - precision: 0.6601 - recall: 0.6601 - auc: 0.6909 - val_loss: 0.6978 - val_accuracy: 0.7014 - val_precision: 0.7014 - val_recall: 0.7014 - val_auc: 0.7342 - 31s/epoch - 112ms/step
Epoch 2/500
275/275 - 17s - loss: 0.7197 - accuracy: 0.6665 - precision: 0.6665 - recall: 0.6665 - auc: 0.7004 - val_loss: 0.9858 - val_accuracy: 0.7014 - val_precision: 0.7014 - val_recall: 0.7014 - val_auc: 0.7259 - 17s/epoch - 60ms/step
Epoch 3/500
275/275 - 16s - loss: 0.8346 - accuracy: 0.6657 - precision: 0.6657 - recall: 0.6657 - auc: 0.6991 - val_loss: 1.1366 - val_accuracy: 0.7014 - val_precision: 0.7014 - val_recall: 0.7014 - val_auc: 0.7302 - 16s/epoch - 60ms/step
Epoch 4/500
275/275 - 16s - loss: 0.8437 - accuracy: 0.6624 - precision: 0.6624 - recall: 0.6624 - auc: 0.6982 - val_loss: 0.7856 - val_accuracy: 0.7014 - val_precision: 0.7014 - val_recall: 0.7014 - val_auc: 0.7281 - 16s/epoch - 60ms/step
Epoch 5/500
275/275 - 16s - loss: 0.8447 - accuracy: 0.6612 - precision: 0.6612 - recall: 0.6612 - auc: 0.6989 - val_loss: 0.7919 - val_accuracy: 0.7014 - val_precision: 0.7014 - val_recall: 0.7014 - val_auc: 0.7209 - 16s/epoch - 60ms/step
Epoch 6/500
275/275 - 16s - loss: 0.8804 - accuracy: 0.6573 - precision: 0.6573 - recall: 0.6573 - auc: 0.6987 - val_loss: 0.8842 - val_accuracy: 0.5257 - val_precision: 0.5257 - val_recall: 0.5257 - val_auc: 0.6301 - 16s/epoch - 59ms/step
Epoch 7/500
275/275 - 16s - loss: 0.9428 - accuracy: 0.6616 - precision: 0.6616 - recall: 0.6616 - auc: 0.6975 - val_loss: 0.8272 - val_accuracy: 0.7014 - val_precision: 0.7014 - val_recall: 0.7014 - val_auc: 0.6776 - 16s/epoch - 60ms/step
Epoch 8/500
275/275 - 16s - loss: 0.8915 - accuracy: 0.6703 - precision: 0.6703 - recall: 0.6703 - auc: 0.7044 - val_loss: 0.8470 - val_accuracy: 0.7014 - val_precision: 0.7014 - val_recall: 0.7014 - val_auc: 0.7253 - 16s/epoch - 60ms/step
Epoch 9/500
275/275 - 16s - loss: 0.8431 - accuracy: 0.6593 - precision: 0.6593 - recall: 0.6593 - auc: 0.6958 - val_loss: 0.7341 - val_accuracy: 0.6976 - val_precision: 0.6976 - val_recall: 0.6976 - val_auc: 0.7286 - 16s/epoch - 59ms/step
Epoch 10/500
