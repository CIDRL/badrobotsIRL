{'activation_function': 'sigmoid', 'batch_size': 128, 'dense_units': 64, 'dropout_rate': 0.8, 'epochs': 500, 'fusion_type': 'early', 'gru_units': 128, 'learning_rate': 0.005, 'loss': 'categorical_crossentropy', 'modality': 'audio', 'num_gru_layers': 2, 'optimizer': 'rmsprop', 'recurrent_regularizer': 'l2', 'sequence_length': 60, 'use_bidirectional': False, 'use_norm': True, 'use_pca': True, 'use_stats': True}
(28611, 24)
(28611, 22)
       frame participant  binary_label  multiclass_label  ...  principal component 18  principal component 19  principal component 20  principal component 21
0          1   p10nodbot             0                 0  ...               -0.201794               -0.268646                0.389261               -0.024862
1          2   p10nodbot             0                 0  ...               -0.140494                0.118213                0.372517                0.053039
2          3   p10nodbot             0                 0  ...                0.023645               -0.386498               -0.071249                0.450963
3          4   p10nodbot             0                 0  ...                0.004169               -0.398274               -0.144599                0.376961
4          5   p10nodbot             0                 0  ...                0.120011                0.118745               -0.114728                0.459980
...      ...         ...           ...               ...  ...                     ...                     ...                     ...                     ...
28606   1038    p9nodbot             0                 0  ...                0.073990               -0.412375                0.373803                0.156319
28607   1039    p9nodbot             0                 0  ...                0.102425               -0.385257                1.022584                1.457676
28608   1040    p9nodbot             0                 0  ...                0.022149               -0.385723                1.040930                1.413527
28609   1041    p9nodbot             0                 0  ...               -0.064762               -0.521244                0.375016                0.109218
28610   1042    p9nodbot             0                 0  ...               -0.000677               -0.354161                1.043381                1.376896

[28611 rows x 26 columns]
Train fold: ['p20nodbot' 'p29nodbot' 'p10nodbot' 'p4nodbot' 'p23nodbot' 'p21nodbot'
 'p26nodbot' 'p11nodbot' 'p7nodbot' 'p17nodbot' 'p12nodbot' 'p25nodbot'
 'p28nodbot' 'p14nodbot' 'p16nodbot' 'p8nodbot']
Validation fold: ['p2nodbot' 'p6nodbot' 'p9nodbot' 'p19nodbot' 'p22nodbot']
Test fold: ['p18nodbot' 'p27nodbot' 'p5nodbot']
Train shapes: (18972, 22) (18972,)
Validation shapes: (5653, 22) (5653,)
Test shapes: (3986, 22) (3986,)
Train sequences shape: (18028, 60, 22) (18028,)
X_train_sequences shape: (18028, 60, 22)
X_val_sequences shape: (5358, 60, 22)
X_test_sequences shape: (3809, 60, 22)
WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 gru (GRU)                   (None, 60, 128)           58368

 dropout (Dropout)           (None, 60, 128)           0

 batch_normalization (Batch  (None, 60, 128)           512
 Normalization)

 gru_1 (GRU)                 (None, 128)               99072

 dropout_1 (Dropout)         (None, 128)               0

 batch_normalization_1 (Bat  (None, 128)               512
 chNormalization)

 dense (Dense)               (None, 64)                8256

 dense_1 (Dense)             (None, 2)                 130

=================================================================
Total params: 166850 (651.76 KB)
Trainable params: 166338 (649.76 KB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
Epoch 1/500
141/141 - 60s - loss: 0.7248 - accuracy: 0.5128 - precision: 0.5128 - recall: 0.5128 - auc: 0.5163 - val_loss: 0.6938 - val_accuracy: 0.4892 - val_precision: 0.4892 - val_recall: 0.4892 - val_auc: 0.5250 - 60s/epoch - 423ms/step
Epoch 2/500
141/141 - 43s - loss: 0.7024 - accuracy: 0.5115 - precision: 0.5115 - recall: 0.5115 - auc: 0.5184 - val_loss: 0.6937 - val_accuracy: 0.4890 - val_precision: 0.4890 - val_recall: 0.4890 - val_auc: 0.4944 - 43s/epoch - 304ms/step
Epoch 3/500
141/141 - 43s - loss: 0.6977 - accuracy: 0.5156 - precision: 0.5156 - recall: 0.5156 - auc: 0.5229 - val_loss: 0.6979 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 4/500
141/141 - 43s - loss: 0.6948 - accuracy: 0.5274 - precision: 0.5274 - recall: 0.5274 - auc: 0.5316 - val_loss: 0.6932 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5212 - 43s/epoch - 305ms/step
Epoch 5/500
141/141 - 43s - loss: 0.6926 - accuracy: 0.5234 - precision: 0.5234 - recall: 0.5234 - auc: 0.5317 - val_loss: 0.6932 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 304ms/step
Epoch 6/500
141/141 - 43s - loss: 0.6919 - accuracy: 0.5321 - precision: 0.5321 - recall: 0.5321 - auc: 0.5343 - val_loss: 0.6936 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 7/500
141/141 - 43s - loss: 0.6915 - accuracy: 0.5342 - precision: 0.5342 - recall: 0.5342 - auc: 0.5320 - val_loss: 0.6932 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 8/500
141/141 - 43s - loss: 0.6908 - accuracy: 0.5350 - precision: 0.5350 - recall: 0.5350 - auc: 0.5376 - val_loss: 0.6931 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 9/500
141/141 - 43s - loss: 0.6909 - accuracy: 0.5349 - precision: 0.5349 - recall: 0.5349 - auc: 0.5363 - val_loss: 0.6941 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 10/500
141/141 - 43s - loss: 0.6909 - accuracy: 0.5355 - precision: 0.5355 - recall: 0.5355 - auc: 0.5370 - val_loss: 0.6943 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 11/500
141/141 - 43s - loss: 0.6908 - accuracy: 0.5359 - precision: 0.5359 - recall: 0.5359 - auc: 0.5347 - val_loss: 0.6944 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 12/500
141/141 - 43s - loss: 0.6908 - accuracy: 0.5357 - precision: 0.5357 - recall: 0.5357 - auc: 0.5322 - val_loss: 0.6937 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 13/500
141/141 - 43s - loss: 0.6908 - accuracy: 0.5360 - precision: 0.5360 - recall: 0.5360 - auc: 0.5348 - val_loss: 0.6947 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 14/500
141/141 - 44s - loss: 0.6908 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5306 - val_loss: 0.6935 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 44s/epoch - 310ms/step
Epoch 15/500
141/141 - 45s - loss: 0.6906 - accuracy: 0.5361 - precision: 0.5361 - recall: 0.5361 - auc: 0.5381 - val_loss: 0.6953 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 45s/epoch - 320ms/step
Epoch 16/500
141/141 - 44s - loss: 0.6908 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5302 - val_loss: 0.6946 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 44s/epoch - 311ms/step
Epoch 17/500
141/141 - 43s - loss: 0.6908 - accuracy: 0.5356 - precision: 0.5356 - recall: 0.5356 - auc: 0.5325 - val_loss: 0.6943 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 18/500
141/141 - 43s - loss: 0.6907 - accuracy: 0.5357 - precision: 0.5357 - recall: 0.5357 - auc: 0.5366 - val_loss: 0.6942 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 19/500
141/141 - 43s - loss: 0.6908 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5349 - val_loss: 0.6952 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 20/500
141/141 - 43s - loss: 0.6907 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5341 - val_loss: 0.6941 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 21/500
141/141 - 43s - loss: 0.6908 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5323 - val_loss: 0.6939 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 22/500
141/141 - 43s - loss: 0.6907 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5327 - val_loss: 0.6937 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 23/500
141/141 - 43s - loss: 0.6907 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5361 - val_loss: 0.6947 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 304ms/step
Epoch 24/500
141/141 - 43s - loss: 0.6907 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5341 - val_loss: 0.6940 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 304ms/step
Epoch 25/500
141/141 - 43s - loss: 0.6908 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5336 - val_loss: 0.6946 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 26/500
141/141 - 43s - loss: 0.6907 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5339 - val_loss: 0.6947 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 304ms/step
Epoch 27/500
141/141 - 43s - loss: 0.6906 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5373 - val_loss: 0.6957 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 28/500
141/141 - 43s - loss: 0.6907 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5351 - val_loss: 0.6958 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 304ms/step
Epoch 29/500
141/141 - 43s - loss: 0.6908 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5332 - val_loss: 0.6944 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 30/500
141/141 - 43s - loss: 0.6907 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5335 - val_loss: 0.6947 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 31/500
141/141 - 43s - loss: 0.6907 - accuracy: 0.5359 - precision: 0.5359 - recall: 0.5359 - auc: 0.5359 - val_loss: 0.6946 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 32/500
141/141 - 43s - loss: 0.6908 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5328 - val_loss: 0.6943 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 33/500
141/141 - 43s - loss: 0.6907 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5343 - val_loss: 0.6938 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 34/500
141/141 - 43s - loss: 0.6908 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5313 - val_loss: 0.6937 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 35/500
141/141 - 43s - loss: 0.6908 - accuracy: 0.5358 - precision: 0.5358 - recall: 0.5358 - auc: 0.5339 - val_loss: 0.6953 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_auc: 0.5110 - 43s/epoch - 305ms/step
Epoch 36/500
[34m[1mwandb[0m: Ctrl + C detected. Stopping sweep.
